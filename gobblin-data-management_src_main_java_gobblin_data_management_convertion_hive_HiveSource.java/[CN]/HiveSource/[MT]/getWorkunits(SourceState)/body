{
  List<WorkUnit> workunits=Lists.newArrayList();
  try {
    HiveSourceWatermarker watermaker=new TableLevelWatermarker(state);
    HiveUnitUpdateProviderFactory updateProviderFactory=GobblinConstructorUtils.invokeConstructor(HiveUnitUpdateProviderFactory.class,state.getProp(OPTIONAL_HIVE_UNIT_UPDATE_PROVIDER_FACTORY_CLASS_KEY,DEFAULT_HIVE_UNIT_UPDATE_PROVIDER_FACTORY_CLASS));
    HiveUnitUpdateProvider updateProvider=updateProviderFactory.create(state);
    IterableDatasetFinder<HiveDataset> datasetFinder=new HiveDatasetFinder(getSourceFs(),state.getProperties());
    Iterator<HiveDataset> iterator=datasetFinder.getDatasetsIterator();
    while (iterator.hasNext()) {
      HiveDataset hiveDataset=iterator.next();
      LongWatermark expectedDatasetHighWatermark=new LongWatermark(new DateTime().getMillis());
      if (HiveUtils.isPartitioned(hiveDataset.getTable())) {
        List<Partition> sourcePartitions=HiveUtils.getPartitions(hiveDataset.getClientPool().getClient().get(),hiveDataset.getTable(),Optional.<String>absent());
        for (        Partition sourcePartition : sourcePartitions) {
          LongWatermark lowWatermark=watermaker.getPreviousHighWatermark(sourcePartition);
          long updateTime=updateProvider.getUpdateTime(sourcePartition);
          if (Long.compare(updateTime,lowWatermark.getValue()) > 0) {
            HivePartition hivePartition=HiveMetaStoreUtils.getHivePartition(sourcePartition.getTPartition());
            WorkUnit workUnit=WorkUnit.createEmpty();
            workUnit.setProp(HIVE_UNIT_SERIALIZED_KEY,GENERICS_AWARE_GSON.toJson(hivePartition,HivePartition.class));
            workUnit.setWatermarkInterval(new WatermarkInterval(lowWatermark,expectedDatasetHighWatermark));
            workUnit.setProp(PARTITION_COMPLETE_NAME_KEY,sourcePartition.getCompleteName());
            workUnit.setProp(ConfigurationKeys.DATASET_URN_KEY,hiveDataset.getTable().getCompleteName());
            workunits.add(workUnit);
          }
 else {
            log.info(String.format("Not creating workunit for partition %s as updateTime %s is lesser than low watermark %s",sourcePartition.getCompleteName(),updateTime,lowWatermark.getValue()));
          }
        }
      }
 else {
        long updateTime=updateProvider.getUpdateTime(hiveDataset.getTable());
        LongWatermark lowWatermark=watermaker.getPreviousHighWatermark(hiveDataset.getTable());
        if (Long.compare(updateTime,lowWatermark.getValue()) > 0) {
          HiveTable hiveTable=HiveMetaStoreUtils.getHiveTable(hiveDataset.getTable().getTTable());
          WorkUnit workUnit=WorkUnit.createEmpty();
          workUnit.setProp(HIVE_UNIT_SERIALIZED_KEY,GENERICS_AWARE_GSON.toJson(hiveTable,HiveTable.class));
          workUnit.setWatermarkInterval(new WatermarkInterval(lowWatermark,expectedDatasetHighWatermark));
          workUnit.setProp(ConfigurationKeys.DATASET_URN_KEY,hiveDataset.getTable().getCompleteName());
          workunits.add(workUnit);
        }
 else {
          log.info(String.format("Not creating workunit for table %s as updateTime %s is lesser than low watermark %s",hiveDataset.getTable().getCompleteName(),updateTime,lowWatermark.getValue()));
        }
      }
    }
  }
 catch (  IOException e) {
    throw new RuntimeException(e);
  }
  return workunits;
}
