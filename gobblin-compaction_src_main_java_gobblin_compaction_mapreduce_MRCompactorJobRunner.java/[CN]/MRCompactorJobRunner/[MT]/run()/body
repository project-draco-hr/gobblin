{
  Configuration conf=HadoopUtils.getConfFromState(this.dataset.jobProps());
  if (conf.get("mapreduce.output.fileoutputformat.compress") == null && conf.get("mapred.output.compress") == null) {
    conf.setBoolean("mapreduce.output.fileoutputformat.compress",true);
  }
  if (conf.get("mapreduce.job.complete.cancel.delegation.tokens") == null) {
    conf.setBoolean("mapreduce.job.complete.cancel.delegation.tokens",false);
  }
  try {
    DateTime compactionTimestamp=getCompactionTimestamp();
    if (this.dataset.jobProps().getPropAsBoolean(MRCompactor.COMPACTION_JOB_LATE_DATA_MOVEMENT_TASK,false)) {
      List<Path> newLateFilePaths=Lists.newArrayList();
      for (      String filePathString : this.dataset.jobProps().getPropAsList(MRCompactor.COMPACTION_JOB_LATE_DATA_FILES)) {
        if (FilenameUtils.isExtension(filePathString,getApplicableFileExtensions())) {
          newLateFilePaths.add(new Path(filePathString));
        }
      }
      Path lateDataOutputPath=this.outputDeduplicated ? this.dataset.outputLatePath() : this.dataset.outputPath();
      LOG.info(String.format("Copying %d late data files to %s",newLateFilePaths.size(),lateDataOutputPath));
      if (this.outputDeduplicated) {
        if (!fs.exists(lateDataOutputPath)) {
          if (!fs.mkdirs(lateDataOutputPath)) {
            throw new RuntimeException(String.format("Failed to create late data output directory: %s.",lateDataOutputPath.toString()));
          }
        }
      }
      this.copyDataFiles(lateDataOutputPath,newLateFilePaths);
      if (this.outputDeduplicated) {
        LOG.info("Getting late record count from: " + this.dataset.outputLatePath());
        this.dataset.checkIfNeedToRecompact(this.lateOutputRecordCountProvider.getRecordCount(this.getApplicableFilePaths(this.dataset.outputLatePath())),this.outputRecordCountProvider.getRecordCount(this.getApplicableFilePaths(this.dataset.outputPath())));
      }
      this.status=Status.COMMITTED;
    }
 else {
      if (this.fs.exists(this.dataset.outputPath()) && !canOverwriteOutputDir()) {
        LOG.warn(String.format("Output path %s exists. Will not compact %s.",this.dataset.outputPath(),this.dataset.inputPath()));
        this.status=Status.COMMITTED;
        return;
      }
      addJars(conf);
      Job job=Job.getInstance(conf);
      this.configureJob(job);
      this.submitAndWait(job);
      if (shouldPublishData(compactionTimestamp)) {
        moveTmpPathToOutputPath();
        if (this.recompactFromDestPaths) {
          deleteAdditionalInputPaths();
        }
        submitSlaEvent(job);
        LOG.info("Successfully published data for input folder " + this.dataset.inputPath());
        this.status=Status.COMMITTED;
      }
 else {
        LOG.info("Data not published for input folder " + this.dataset.inputPath() + " due to incompleteness");
        this.status=Status.ABORTED;
        return;
      }
    }
    this.markOutputDirAsCompleted(compactionTimestamp);
    this.submitRecordsCountsEvent();
  }
 catch (  Throwable t) {
    throw Throwables.propagate(t);
  }
}
