{
  Preconditions.checkNotNull(outputAvroSchema,"Avro schema must not be null");
  Preconditions.checkNotNull(conversionEntity,"Conversion entity must not be null");
  Preconditions.checkNotNull(workUnit,"Workunit state must not be null");
  Preconditions.checkNotNull(conversionEntity.getHiveTable(),"Hive table within conversion entity must not be null");
  this.hiveDataset=conversionEntity.getConvertibleHiveDataset();
  if (!hasConversionConfig()) {
    return new SingleRecordIterable<>(conversionEntity);
  }
  String avroTableName=conversionEntity.getHiveTable().getTableName();
  String orcTableName=getConversionConfig().getDestinationTableName();
  String orcStagingTableName=getConversionConfig().getDestinationStagingTableName();
  String orcTableDatabase=getConversionConfig().getDestinationDbName();
  String orcDataLocation=getOrcDataLocation(workUnit);
  boolean isEvolutionEnabled=getConversionConfig().isEvolutionEnabled();
  Optional<Table> destinationTableMeta=getDestinationTableMeta(orcTableDatabase,orcTableName,workUnit);
  Optional<List<String>> clusterBy=getConversionConfig().getClusterBy().isEmpty() ? Optional.<List<String>>absent() : Optional.of(getConversionConfig().getClusterBy());
  Optional<Integer> numBuckets=getConversionConfig().getNumBuckets();
  Optional<Integer> rowLimit=getConversionConfig().getRowLimit();
  Map<String,String> partitionsDDLInfo=Maps.newHashMap();
  Map<String,String> partitionsDMLInfo=Maps.newHashMap();
  populatePartitionInfo(conversionEntity,partitionsDDLInfo,partitionsDMLInfo);
  for (  Map.Entry<Object,Object> entry : getConversionConfig().getHiveRuntimeProperties().entrySet()) {
    conversionEntity.getQueries().add(String.format("SET %s=%s;",entry.getKey(),entry.getValue()));
  }
  Map<String,String> hiveColumns=new HashMap<String,String>();
  String createTargetTableDDL=HiveAvroORCQueryGenerator.generateCreateTableDDL(outputAvroSchema,orcStagingTableName,orcDataLocation,Optional.of(orcTableDatabase),Optional.of(partitionsDDLInfo),clusterBy,Optional.<Map<String,HiveAvroORCQueryGenerator.COLUMN_SORT_ORDER>>absent(),numBuckets,Optional.<String>absent(),Optional.<String>absent(),Optional.<String>absent(),Optional.<Map<String,String>>absent(),isEvolutionEnabled,destinationTableMeta,hiveColumns);
  conversionEntity.getQueries().add(createTargetTableDDL);
  log.debug("Create DDL: " + createTargetTableDDL);
  String insertInORCTableDML=HiveAvroORCQueryGenerator.generateTableMappingDML(conversionEntity.getHiveTable().getAvroSchema(),outputAvroSchema,avroTableName,orcStagingTableName,Optional.of(conversionEntity.getHiveTable().getDbName()),Optional.of(orcTableDatabase),Optional.of(partitionsDMLInfo),Optional.<Boolean>absent(),Optional.<Boolean>absent(),isEvolutionEnabled,destinationTableMeta,rowLimit);
  conversionEntity.getQueries().add(insertInORCTableDML);
  log.debug("Conversion DML: " + insertInORCTableDML);
  StringBuilder publishTableQueries=new StringBuilder();
  publishTableQueries.append(HiveAvroORCQueryGenerator.generateEvolutionDDL(orcStagingTableName,orcTableName,Optional.of(orcTableDatabase),Optional.of(orcTableDatabase),outputAvroSchema,isEvolutionEnabled,hiveColumns,destinationTableMeta)).append("\n");
  publishTableQueries.append(HiveAvroORCQueryGenerator.generatePublishTableDDL(orcStagingTableName,orcTableName,Optional.of(orcTableDatabase),Optional.of(orcTableDatabase),destinationTableMeta)).append("\n");
  HiveAvroORCQueryGenerator.serializePublishTableCommands(workUnit,publishTableQueries.toString());
  log.debug("Publish table queries: " + publishTableQueries);
  StringBuilder publishPartitionQueries=new StringBuilder();
  publishPartitionQueries.append(HiveAvroORCQueryGenerator.generatePublishPartitionDDL(orcStagingTableName,orcTableName,Optional.of(orcTableDatabase),Optional.of(orcTableDatabase),partitionsDMLInfo,destinationTableMeta)).append("\n");
  HiveAvroORCQueryGenerator.serializePublishPartitionCommands(workUnit,publishPartitionQueries.toString());
  log.debug("Publish partition queries: " + publishPartitionQueries);
  StringBuilder cleanupQueries=new StringBuilder();
  cleanupQueries.append(HiveAvroORCQueryGenerator.generateCleanupDDL(orcStagingTableName,Optional.of(orcTableDatabase))).append("\n");
  HiveAvroORCQueryGenerator.serializedCleanupCommands(workUnit,cleanupQueries.toString());
  log.debug("Cleanup queries: " + cleanupQueries);
  log.debug("Conversion Query " + conversionEntity.getQueries());
  return new SingleRecordIterable<>(conversionEntity);
}
