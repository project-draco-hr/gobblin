{
  Preconditions.checkArgument(!datasetWorkUnitStates.isEmpty(),"publishDataset received an empty collection work units. This is an error in code.");
  CopyableDatasetMetadata metadata=CopyableDatasetMetadata.deserialize(datasetWorkUnitStates.iterator().next().getProp(CopySource.SERIALIZED_COPYABLE_DATASET));
  Path datasetWriterOutputPath=new Path(new Path(writerOutputDir,datasetAndPartition.identifier()),PathUtils.withoutLeadingSeparator(metadata.getDatasetTargetRoot()));
  log.info(String.format("Publishing dataset from %s to %s",datasetWriterOutputPath,metadata.getDatasetTargetRoot()));
  HadoopUtils.renameRecursively(fs,datasetWriterOutputPath,metadata.getDatasetTargetRoot());
  fs.delete(datasetWriterOutputPath,true);
  for (  WorkUnitState wus : datasetWorkUnitStates) {
    if (wus.getWorkingState() == WorkingState.SUCCESSFUL) {
      wus.setWorkingState(WorkUnitState.WorkingState.COMMITTED);
      CopyEventSubmitterHelper.submitSuccessfulFilePublish(eventSubmitter,wus);
    }
  }
  CopyEventSubmitterHelper.submitSuccessfulDatasetPublish(eventSubmitter,datasetAndPartition);
}
