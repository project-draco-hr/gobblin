{
  for (  String name : this.jobProps.stringPropertyNames()) {
    this.conf.set(name,this.jobProps.getProperty(name));
  }
  this.conf.set("mapred.max.map.failures.percent","100");
  this.conf.set("mapreduce.map.failures.maxpercent","100");
  this.conf.setBoolean("mapreduce.job.complete.cancel.delegation.tokens",false);
  this.mrJobDir=new Path(this.jobProps.getProperty(ConfigurationKeys.MR_JOB_ROOT_DIR_KEY),this.jobName);
  if (this.fs.exists(this.mrJobDir)) {
    LOG.warn("Job working directory already exists for job " + this.jobName);
    this.fs.delete(this.mrJobDir,true);
  }
  JobLauncherUtils.cleanStagingData(JobLauncherUtils.flattenWorkUnits(workUnits),LOG);
  try {
    Path jobOutputPath=prepareHadoopJob(this.jobName,this.jobProps,workUnits);
    LOG.info("Launching Hadoop MR job " + this.job.getJobName());
    this.job.submit();
    if (!this.jobState.contains(ConfigurationKeys.JOB_TRACKING_URL_KEY)) {
      this.jobState.setProp(ConfigurationKeys.JOB_TRACKING_URL_KEY,this.job.getTrackingURL());
    }
    this.job.waitForCompletion(true);
    if (this.isCancelled) {
      this.jobState.setState(JobState.RunningState.CANCELLED);
      return;
    }
    this.jobState.setState(this.job.isSuccessful() ? JobState.RunningState.SUCCESSFUL : JobState.RunningState.FAILED);
    this.jobState.addTaskStates(collectOutput(new Path(jobOutputPath,this.jobProps.getProperty(ConfigurationKeys.JOB_ID_KEY))));
    countersToMetrics(this.job.getCounters(),JobMetrics.get(this.jobName,this.jobProps.getProperty(ConfigurationKeys.JOB_ID_KEY)));
  }
  finally {
    cleanUpWorkingDirectory();
  }
}
