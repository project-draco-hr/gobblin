{
  for (  String name : this.jobProps.stringPropertyNames()) {
    this.conf.set(name,this.jobProps.getProperty(name));
  }
  this.conf.set("mapred.max.map.failures.percent","100");
  this.conf.set("mapreduce.map.failures.maxpercent","100");
  this.conf.setBoolean("mapreduce.job.complete.cancel.delegation.tokens",false);
  String jobName=this.jobContext.getJobName();
  JobState jobState=this.jobContext.getJobState();
  Path mrJobDir=new Path(this.jobProps.getProperty(ConfigurationKeys.MR_JOB_ROOT_DIR_KEY),jobName);
  if (this.fs.exists(mrJobDir)) {
    LOG.warn("Job working directory already exists for job " + jobName);
    this.fs.delete(mrJobDir,true);
  }
  try {
    JobLauncherUtils.cleanStagingData(JobLauncherUtils.flattenWorkUnits(workUnits),LOG);
    Path jobOutputPath=prepareHadoopJob(this.jobProps,workUnits,mrJobDir);
    LOG.info("Launching Hadoop MR job " + this.job.getJobName());
    this.job.submit();
    if (!jobState.contains(ConfigurationKeys.JOB_TRACKING_URL_KEY)) {
      jobState.setProp(ConfigurationKeys.JOB_TRACKING_URL_KEY,this.job.getTrackingURL());
    }
    LOG.info(String.format("Waiting for Hadoop MR job %s to complete",this.job.getJobID()));
    this.job.waitForCompletion(true);
    if (this.cancellationRequested) {
synchronized (this.cancellationExecution) {
        if (jobState.getState() == JobState.RunningState.CANCELLED) {
          LOG.info(String.format("Job %s has been cancelled, aborting now",this.jobContext.getJobId()));
          return;
        }
      }
    }
    jobState.setState(this.job.isSuccessful() ? JobState.RunningState.SUCCESSFUL : JobState.RunningState.FAILED);
    jobState.addTaskStates(collectOutput(new Path(jobOutputPath,this.jobProps.getProperty(ConfigurationKeys.JOB_ID_KEY))));
    countersToMetrics(this.job.getCounters(),JobMetrics.get(jobName,this.jobProps.getProperty(ConfigurationKeys.JOB_ID_KEY)));
  }
  finally {
    cleanUpWorkingDirectory();
  }
}
