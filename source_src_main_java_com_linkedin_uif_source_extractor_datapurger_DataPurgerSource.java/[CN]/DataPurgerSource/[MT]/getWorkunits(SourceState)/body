{
  initLogger(state);
  this.fsHelper=initFileSystemHelper(state);
  log.info("Getting work units");
  String nameSpaceName=state.getProp(ConfigurationKeys.EXTRACT_NAMESPACE_NAME_KEY);
  String entityName=state.getProp(ConfigurationKeys.SOURCE_ENTITY);
  String extractTableName=state.getProp(ConfigurationKeys.EXTRACT_TABLE_NAME_KEY);
  if (Strings.isNullOrEmpty(extractTableName)) {
    extractTableName=entityName;
  }
  TableType tableType=TableType.valueOf(state.getProp(ConfigurationKeys.EXTRACT_TABLE_TYPE_KEY).toUpperCase());
  List<String> filesToPull=new ArrayList<String>();
  List<String> whitelist=state.getPropAsList(DATA_PURGER_WHITELIST);
  HadoopFsHelper fsHelper=(HadoopFsHelper)this.fsHelper;
  FileSystem fs=fsHelper.getFileSystem();
  try {
    for (    FileStatus status : fs.listStatus(new Path(state.getProp(DATA_PURGER_INPUT_PATH)))) {
      String topicName=status.getPath().getName();
      if (whitelist.contains(topicName)) {
        addAllInputFiles(fs,new Path(status.getPath(),DAILY_FOLDER),filesToPull);
      }
    }
  }
 catch (  IOException e) {
    Throwables.propagate(e);
  }
  int workUnitCount=0;
  List<WorkUnit> workUnits=Lists.newArrayList();
  for (  String file : filesToPull) {
    SourceState partitionState=new SourceState();
    partitionState.addAll(state);
    partitionState.setProp(ConfigurationKeys.SOURCE_FILEBASED_FILES_TO_PULL,file);
    if (state.getPropAsBoolean(ConfigurationKeys.SOURCE_FILEBASED_PRESERVE_FILE_PATH,false)) {
      partitionState.setProp(ConfigurationKeys.DATA_PUBLISHER_FINAL_DIR,new Path(file).getParent().toString());
      partitionState.setProp(ConfigurationKeys.DATA_PUBLISHER_FINAL_NAME,new Path(file).getName().toString());
    }
    Extract extract=partitionState.createExtract(tableType,nameSpaceName,extractTableName);
    workUnits.add(partitionState.createWorkUnit(extract));
    workUnitCount++;
  }
  log.info("Total number of work units for the current run: " + workUnitCount);
  return workUnits;
}
