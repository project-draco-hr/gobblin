{
  String topic="testAvroSerialization";
  _kafkaTestHelper.provisionTopic(topic);
  Properties props=new Properties();
  props.setProperty(KafkaWriterConfigurationKeys.KAFKA_TOPIC,topic);
  props.setProperty(KafkaWriterConfigurationKeys.KAFKA_PRODUCER_CONFIG_PREFIX + "bootstrap.servers","localhost:" + _kafkaTestHelper.getKafkaServerPort());
  props.setProperty(KafkaWriterConfigurationKeys.KAFKA_PRODUCER_CONFIG_PREFIX + "value.serializer","gobblin.kafka.serialize.LiAvroSerializer");
  props.setProperty(KafkaWriterConfigurationKeys.KAFKA_PRODUCER_CONFIG_PREFIX + KafkaSchemaRegistryConfigurationKeys.KAFKA_SCHEMA_REGISTRY_CLASS,ConfigDrivenMd5SchemaRegistry.class.getCanonicalName());
  KafkaDataWriter<GenericRecord> kafkaWriter=new KafkaDataWriter<>(props);
  GenericRecord record=KafkaTestUtils.generateRandomAvroRecord();
  try {
    kafkaWriter.write(record);
    kafkaWriter.commit();
  }
  finally {
    kafkaWriter.close();
  }
  Assert.assertEquals(kafkaWriter.recordsWritten(),1);
  byte[] message=_kafkaTestHelper.getIteratorForTopic(topic).next().message();
  ConfigDrivenMd5SchemaRegistry schemaReg=new ConfigDrivenMd5SchemaRegistry(topic,record.getSchema());
  LiAvroDeserializer deser=new LiAvroDeserializer(schemaReg);
  GenericRecord receivedRecord=deser.deserialize(topic,message);
  System.out.println(record.toString());
  System.out.println(receivedRecord.toString());
}
