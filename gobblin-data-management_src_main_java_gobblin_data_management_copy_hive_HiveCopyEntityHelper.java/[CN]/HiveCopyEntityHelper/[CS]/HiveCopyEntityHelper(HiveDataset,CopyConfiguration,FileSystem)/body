{
  try (Closer closer=Closer.create()){
    log.info("Finding copy entities for table " + dataset.table.getCompleteName());
    this.eventSubmitter=new EventSubmitter.Builder(dataset.getMetricContext(),"hive.dataset.copy").build();
    MultiTimingEvent multiTimer=closer.register(new MultiTimingEvent(this.eventSubmitter,"HiveCopySetup",true));
    this.startTime=System.currentTimeMillis();
    this.dataset=dataset;
    this.configuration=configuration;
    this.targetFs=targetFs;
    this.hiveRegProps=new HiveRegProps(new State(this.dataset.getProperties()));
    this.targetURI=Optional.fromNullable(this.dataset.getProperties().getProperty(TARGET_METASTORE_URI_KEY));
    this.targetClientPool=HiveMetastoreClientPool.get(this.dataset.getProperties(),this.targetURI);
    this.targetDatabase=Optional.fromNullable(this.dataset.getProperties().getProperty(TARGET_DATABASE_KEY)).or(this.dataset.table.getDbName());
    this.existingEntityPolicy=ExistingEntityPolicy.valueOf(this.dataset.getProperties().getProperty(EXISTING_ENTITY_POLICY_KEY,DEFAULT_EXISTING_ENTITY_POLICY).toUpperCase());
    this.deleteMethod=this.dataset.getProperties().containsKey(DELETE_FILES_ON_DEREGISTER) ? DeregisterFileDeleteMethod.valueOf(this.dataset.getProperties().getProperty(DELETE_FILES_ON_DEREGISTER).toUpperCase()) : DEFAULT_DEREGISTER_DELETE_METHOD;
    if (this.dataset.getProperties().containsKey(COPY_PARTITION_FILTER_GENERATOR)) {
      try {
        PartitionFilterGenerator generator=GobblinConstructorUtils.invokeFirstConstructor((Class<PartitionFilterGenerator>)Class.forName(this.dataset.getProperties().getProperty(COPY_PARTITION_FILTER_GENERATOR)),Lists.<Object>newArrayList(this.dataset.getProperties()),Lists.newArrayList());
        this.partitionFilter=Optional.of(generator.getFilter(this.dataset));
        log.info(String.format("Dynamic partition filter for table %s: %s.",this.dataset.table.getCompleteName(),this.partitionFilter.get()));
      }
 catch (      ReflectiveOperationException roe) {
        throw new IOException(roe);
      }
    }
 else {
      this.partitionFilter=Optional.fromNullable(this.dataset.getProperties().getProperty(COPY_PARTITIONS_FILTER_CONSTANT));
    }
    try {
      this.fastPartitionSkip=this.dataset.getProperties().containsKey(FAST_PARTITION_SKIP_PREDICATE) ? Optional.of(GobblinConstructorUtils.invokeFirstConstructor((Class<Predicate<PartitionCopy>>)Class.forName(this.dataset.getProperties().getProperty(FAST_PARTITION_SKIP_PREDICATE)),Lists.<Object>newArrayList(this),Lists.newArrayList())) : Optional.<Predicate<PartitionCopy>>absent();
    }
 catch (    ReflectiveOperationException roe) {
      closer.close();
      throw new IOException(roe);
    }
    Map<String,HiveMetastoreClientPool> namedPools=ImmutableMap.of(source_client,this.dataset.clientPool,target_client,this.targetClientPool);
    multiTimer.nextStage(Stages.GET_TABLES);
    try (HiveMetastoreClientPool.MultiClient multiClient=HiveMetastoreClientPool.safeGetClients(namedPools)){
      if (multiClient.getClient(target_client).tableExists(this.targetDatabase,this.dataset.table.getTableName())) {
        this.existingTargetTable=Optional.of(new Table(multiClient.getClient(target_client).getTable(this.targetDatabase,this.dataset.table.getTableName())));
      }
 else {
        this.existingTargetTable=Optional.absent();
      }
      Path targetPath=getTargetLocation(dataset.fs,this.targetFs,dataset.table.getDataLocation(),Optional.<Partition>absent());
      this.targetTable=getTargetTable(this.dataset.table,targetPath);
      HiveSpec tableHiveSpec=new SimpleHiveSpec.Builder<>(targetPath).withTable(HiveMetaStoreUtils.getHiveTable(this.targetTable.getTTable())).build();
      CommitStep tableRegistrationStep=new HiveRegisterStep(this.targetURI,tableHiveSpec,this.hiveRegProps);
      this.tableRegistrationStep=Optional.of(tableRegistrationStep);
      if (this.existingTargetTable.isPresent() && this.existingTargetTable.get().isPartitioned()) {
        checkPartitionedTableCompatibility(this.targetTable,this.existingTargetTable.get());
      }
      if (HiveUtils.isPartitioned(this.dataset.table)) {
        this.sourcePartitions=HiveUtils.getPartitionsMap(multiClient.getClient(source_client),this.dataset.table,this.partitionFilter);
        this.targetPartitions=this.existingTargetTable.isPresent() ? HiveUtils.getPartitionsMap(multiClient.getClient(target_client),this.existingTargetTable.get(),this.partitionFilter) : Maps.<List<String>,Partition>newHashMap();
      }
 else {
        this.sourcePartitions=Maps.newHashMap();
        this.targetPartitions=Maps.newHashMap();
      }
      this.targetPathHelper=new HiveTargetPathHelper(this.dataset);
    }
 catch (    TException te) {
      closer.close();
      throw new IOException("Failed to generate work units for table " + dataset.table.getCompleteName(),te);
    }
  }
 }
