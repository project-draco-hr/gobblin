{
  log.info("Finding copy entities for table " + dataset.table.getCompleteName());
  this.startTime=System.currentTimeMillis();
  this.dataset=dataset;
  this.configuration=configuration;
  this.targetFs=targetFs;
  this.relocateDataFiles=Boolean.valueOf(this.dataset.properties.getProperty(RELOCATE_DATA_FILES_KEY,DEFAULT_RELOCATE_DATA_FILES));
  this.targetTableRoot=this.dataset.properties.containsKey(COPY_TARGET_TABLE_ROOT) ? Optional.of(resolvePath(this.dataset.properties.getProperty(COPY_TARGET_TABLE_ROOT),this.dataset.table.getDbName(),this.dataset.table.getTableName())) : Optional.<Path>absent();
  this.hiveRegProps=new HiveRegProps(new State(this.dataset.properties));
  this.targetURI=Optional.fromNullable(this.dataset.properties.getProperty(TARGET_METASTORE_URI_KEY));
  this.targetClientPool=HiveMetastoreClientPool.get(this.dataset.properties,this.targetURI);
  this.targetDatabase=Optional.fromNullable(this.dataset.properties.getProperty(TARGET_DATABASE_KEY)).or(this.dataset.table.getDbName());
  this.existingEntityPolicy=ExistingEntityPolicy.valueOf(this.dataset.properties.getProperty(EXISTING_ENTITY_POLICY_KEY,DEFAULT_EXISTING_ENTITY_POLICY).toUpperCase());
  if (this.dataset.properties.containsKey(COPY_PARTITION_FILTER_GENERATOR)) {
    try {
      PartitionFilterGenerator generator=GobblinConstructorUtils.invokeFirstConstructor((Class<PartitionFilterGenerator>)Class.forName(this.dataset.properties.getProperty(COPY_PARTITION_FILTER_GENERATOR)),Lists.<Object>newArrayList(this.dataset.properties),Lists.newArrayList());
      this.partitionFilter=Optional.of(generator.getFilter(this.dataset));
      log.info(String.format("Dynamic partition filter for table %s: %s.",this.dataset.table.getCompleteName(),this.partitionFilter.get()));
    }
 catch (    ReflectiveOperationException roe) {
      throw new IOException(roe);
    }
  }
 else {
    this.partitionFilter=Optional.fromNullable(this.dataset.properties.getProperty(COPY_PARTITIONS_FILTER_CONSTANT));
  }
  try {
    this.fastPartitionSkip=this.dataset.properties.containsKey(FAST_PARTITION_SKIP_PREDICATE) ? Optional.of(GobblinConstructorUtils.invokeFirstConstructor((Class<Predicate<PartitionCopy>>)Class.forName(this.dataset.properties.getProperty(FAST_PARTITION_SKIP_PREDICATE)),Lists.<Object>newArrayList(this),Lists.newArrayList())) : Optional.<Predicate<PartitionCopy>>absent();
  }
 catch (  ReflectiveOperationException roe) {
    throw new IOException(roe);
  }
  Map<String,HiveMetastoreClientPool> namedPools=ImmutableMap.of(source_client,this.dataset.clientPool,target_client,this.targetClientPool);
  try (HiveMetastoreClientPool.MultiClient multiClient=HiveMetastoreClientPool.safeGetClients(namedPools)){
    if (multiClient.getClient(target_client).tableExists(targetDatabase,this.dataset.table.getTableName())) {
      this.existingTargetTable=Optional.of(new Table(multiClient.getClient(target_client).getTable(targetDatabase,this.dataset.table.getTableName())));
    }
 else {
      this.existingTargetTable=Optional.absent();
    }
    Path targetPath=getTargetLocation(dataset.fs,this.targetFs,dataset.table.getDataLocation(),Optional.<Partition>absent());
    this.targetTable=getTargetTable(this.dataset.table,targetPath);
    HiveSpec tableHiveSpec=new SimpleHiveSpec.Builder<>(targetPath).withTable(HiveMetaStoreUtils.getHiveTable(this.targetTable.getTTable())).build();
    CommitStep tableRegistrationStep=new HiveRegisterStep(targetURI,tableHiveSpec,this.hiveRegProps);
    this.tableRegistrationStep=Optional.of(tableRegistrationStep);
    if (this.existingTargetTable.isPresent()) {
      checkTableCompatibility(this.targetTable,this.existingTargetTable.get());
    }
    if (HiveUtils.isPartitioned(this.dataset.table)) {
      this.sourcePartitions=HiveUtils.getPartitionsMap(multiClient.getClient(source_client),this.dataset.table,this.partitionFilter);
      this.targetPartitions=this.existingTargetTable.isPresent() ? HiveUtils.getPartitionsMap(multiClient.getClient(target_client),this.existingTargetTable.get(),this.partitionFilter) : Maps.<List<String>,Partition>newHashMap();
    }
 else {
      this.sourcePartitions=Maps.newHashMap();
      this.targetPartitions=Maps.newHashMap();
    }
  }
 catch (  TException te) {
    throw new IOException("Failed to generate work units for table " + dataset.table.getCompleteName(),te);
  }
}
